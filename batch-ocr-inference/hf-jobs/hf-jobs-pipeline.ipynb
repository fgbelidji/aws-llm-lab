{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Batch Document OCR with HF jobs\n",
    "\n",
    "This notebook runs a three-stage OCR pipeline on Hugging Face Jobs:\n",
    "\n",
    "1. **Extract** – Run DeepSeek OCR over a dataset, save Markdown and crop detected figures\n",
    "2. **Describe** – Generate captions for extracted figures  \n",
    "3. **Assemble** – Enrich Markdown with figure captions\n",
    "\n",
    "All stages share a single HF dataset repository. Each stage loads the dataset, processes it, and pushes updates back.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from huggingface_hub import HfApi, create_repo, fetch_job_logs, inspect_job, run_uv_job, whoami\n",
    "from huggingface_hub._jobs_api import JobInfo, JobStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "USERNAME = whoami()[\"name\"]\n",
    "\n",
    "HUB_IMAGE = \"vllm/vllm-openai:v0.12.0\"\n",
    "HARDWARE = \"a100-large\"\n",
    "TIMEOUT = \"3h\"\n",
    "\n",
    "CODE_REPO = f\"{USERNAME}/deepseek-ocr-job-code\"\n",
    "DATASET_REPO = f\"{USERNAME}/deepseek-ocr-dataset\"\n",
    "\n",
    "# Source dataset\n",
    "SOURCE_DATASET = \"HuggingFaceM4/FineVision\"\n",
    "SOURCE_CONFIG = \"olmOCR-mix-0225-documents\"\n",
    "MAX_SAMPLES = 20\n",
    "\n",
    "print(f\"Code: {CODE_REPO} | Dataset: {DATASET_REPO}\")\n",
    "print(f\"Source: {SOURCE_DATASET}/{SOURCE_CONFIG} ({MAX_SAMPLES} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base environment for all stages\n",
    "BASE_ENV = {\n",
    "    # vLLM\n",
    "    \"MODEL_ID\": \"deepseek-ai/DeepSeek-OCR\",\n",
    "    \"SERVED_MODEL_NAME\": \"deepseek-ocr\",\n",
    "    \"HOST\": \"0.0.0.0\",\n",
    "    \"PORT\": \"8000\",\n",
    "    \"MAX_MODEL_LEN\": \"8192\",\n",
    "    \"GPU_MEMORY_UTILIZATION\": \"0.90\",\n",
    "    \"TENSOR_PARALLEL_SIZE\": \"1\",\n",
    "    # Code\n",
    "    \"JOB_CODE_REPO\": CODE_REPO,\n",
    "    \"JOB_CODE_REVISION\": \"main\",\n",
    "    \"JOB_CODE_LOCAL_DIR\": \"/tmp/deepseek-ocr-job-code\",\n",
    "    # Auth\n",
    "    \"HF_TOKEN\": os.environ.get(\"HF_TOKEN\", \"\"),\n",
    "    # Prompts\n",
    "    \"DOC_PROMPT\": \"<image>\\n<|grounding|>Convert this document to Markdown.\",\n",
    "    \"DOC_MAX_TOKENS\": \"4096\",\n",
    "    \"DOC_TEMPERATURE\": \"0.1\",\n",
    "    \"FIGURE_PROMPT\": \"<image>\\nDescribe this image in detail.\",\n",
    "    \"FIGURE_MAX_TOKENS\": \"512\",\n",
    "    \"FIGURE_TEMPERATURE\": \"0.6\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload code to HF Hub\n",
    "CODE_PATHS = [\n",
    "    Path(\"hf_job_runner.py\"),\n",
    "    Path(\"../llm_ocr\"),\n",
    "]\n",
    "\n",
    "api = HfApi()\n",
    "create_repo(repo_id=CODE_REPO, repo_type=\"dataset\", exist_ok=True)\n",
    "create_repo(repo_id=DATASET_REPO, repo_type=\"dataset\", exist_ok=True)\n",
    "\n",
    "bundle_dir = Path(tempfile.mkdtemp(prefix=\"job-code-\"))\n",
    "for path in CODE_PATHS:\n",
    "    src = Path.cwd() / path if not path.is_absolute() else path\n",
    "    if src.is_dir():\n",
    "        shutil.copytree(src, bundle_dir / path.name, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(src, bundle_dir / path.name)\n",
    "\n",
    "api.upload_folder(folder_path=str(bundle_dir), repo_id=CODE_REPO, repo_type=\"dataset\")\n",
    "print(f\"Uploaded code to {CODE_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "CODE_URL = f\"https://huggingface.co/datasets/{CODE_REPO}/resolve/main/hf_job_runner.py\"\n",
    "\n",
    "def launch(stage: str, flavor: str, env: dict) -> JobInfo:\n",
    "    full_env = {**BASE_ENV, **env, \"PIPELINE_STAGE\": stage}\n",
    "    job = run_uv_job(CODE_URL, image=HUB_IMAGE, flavor=flavor, env=full_env, timeout=TIMEOUT)\n",
    "    print(f\"Launched {stage}: {job.url}\")\n",
    "    return job\n",
    "\n",
    "def wait(job: JobInfo, poll: int = 60) -> JobInfo:\n",
    "    while True:\n",
    "        info = inspect_job(job_id=job.id)\n",
    "        stage = info.status.stage\n",
    "        print(f\"  {job.id}: {stage}\")\n",
    "        if stage not in {JobStage.RUNNING, \"RUNNING\", \"UPDATING\"}:\n",
    "            return info\n",
    "        time.sleep(poll)\n",
    "\n",
    "def logs(job: JobInfo, tail: int = 100):\n",
    "    for line in list(fetch_job_logs(job_id=job.id, namespace=job.owner.name))[-tail:]:\n",
    "        print(line, end=\"\")\n",
    "\n",
    "\n",
    "# Import rendering utilities from llm_ocr\n",
    "import sys\n",
    "sys.path.insert(0, '..')  # Add parent directory for llm_ocr imports\n",
    "from llm_ocr.document import render_sample_markdown, display_markdown\n",
    "\n",
    "\n",
    "def display_samples(dataset, num_samples: int = 2):\n",
    "    \"\"\"Display a few samples from the dataset.\"\"\"\n",
    "    from IPython.display import display, Markdown\n",
    "    \n",
    "    print(f\"Dataset: {len(dataset)} samples\")\n",
    "    print(f\"Columns: {list(dataset.column_names)}\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        sample = dataset[i]\n",
    "        print(f\"=== Sample {i}: {sample['sample_id']} ===\")\n",
    "        \n",
    "        # Show source image if available\n",
    "        if sample.get('source_image'):\n",
    "            print(\"Source image:\")\n",
    "            display(sample['source_image'])\n",
    "        \n",
    "        # Show markdown preview\n",
    "        md = sample.get('document_markdown') or sample.get('document_markdown_text', '')\n",
    "        if md:\n",
    "            print(f\"\\nMarkdown preview ({len(md)} chars):\")\n",
    "            print(md[:500] + '...' if len(md) > 500 else md)\n",
    "        \n",
    "        # Show final markdown if available\n",
    "        final_md = sample.get('document_final_markdown') or sample.get('document_final_markdown_text', '')\n",
    "        if final_md:\n",
    "            print(f\"\\nFinal markdown preview ({len(final_md)} chars):\")\n",
    "            print(final_md[:500] + '...' if len(final_md) > 500 else final_md)\n",
    "        \n",
    "        # Show figures\n",
    "        figures = sample.get('extracted_figures', [])\n",
    "        if figures:\n",
    "            print(f\"\\nExtracted figures: {len(figures)}\")\n",
    "            for j, fig in enumerate(figures[:2]):  # Show max 2 figures\n",
    "                display(fig)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Extract\n",
    "stage1 = launch(\"extract\", flavor=HARDWARE, env={\n",
    "    \"DATASET_NAME\": SOURCE_DATASET,\n",
    "    \"DATASET_CONFIG\": SOURCE_CONFIG,\n",
    "    \"DATASET_SPLIT\": \"train\",\n",
    "    \"MAX_SAMPLES\": str(MAX_SAMPLES),\n",
    "    \"OUTPUT_DIR\": \"./outputs\",\n",
    "    \"EXTRACT_BATCH_SIZE\": \"256\",\n",
    "    \"EXTRACT_MAX_CONCURRENCY\": \"8\",\n",
    "    \"HF_REPO_ID\": DATASET_REPO,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_done = wait(stage1)\n",
    "print(f\"Extract complete: {DATASET_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display samples after Extract\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds_extract = load_dataset(DATASET_REPO, split=\"train\")\n",
    "display_samples(ds_extract, num_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Describe\n",
    "# Updates dataset in place (same repo)\n",
    "stage2 = launch(\"describe\", flavor=HARDWARE, env={\n",
    "    \"OUTPUT_DIR\": \"./outputs\",\n",
    "    \"DESCRIBE_BATCH_SIZE\": \"8\",\n",
    "    \"DESCRIBE_MAX_CONCURRENCY\": \"4\",\n",
    "    \"SOURCE_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_REPO_ID\": DATASET_REPO,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_done = wait(stage2)\n",
    "print(f\"Describe complete: {DATASET_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "# Load and display samples after Describe\n",
    "ds_describe = load_dataset(DATASET_REPO, split=\"train\")\n",
    "display_samples(ds_describe, num_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Assemble\n",
    "# Updates dataset in place + saves final markdown files\n",
    "stage3 = launch(\"assemble\", flavor='cpu-upgrade', env={\n",
    "    \"OUTPUT_DIR\": \"./outputs\",\n",
    "    \"SOURCE_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_COMMIT_MESSAGE\": \"Add assembled documents with figure captions\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage3_done = wait(stage3)\n",
    "print(f\"Pipeline complete! Dataset: https://huggingface.co/datasets/{DATASET_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display final samples after Assemble\n",
    "ds_final = load_dataset(DATASET_REPO, split=\"train\")\n",
    "display_samples(ds_final, num_samples=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
